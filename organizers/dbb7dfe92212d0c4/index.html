<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=google-site-verification content="MLZcoHabOaOhGgVXj2nNafdpQ0aRkBiCOBUgD6XM6bs"><link rel="shortcut icon" href=/favicon.ico><title>László A. Jeni -
The 20th IEEE International Conference on Automatic Face and Gesture Recognition</title><meta name=description content="The IEEE conference series on Automatic Face and Gesture Recognition is the premier international forum for research in image and video-based face, gesture, and body movement recognition. It is co-sponsored by IEEE Biometrics Council and IEEE Computer Society . Its broad scope includes advances in fundamental computer vision, pattern recognition, and computer graphics; machine learning techniques relevant to face, gesture, and body motion; interdisciplinary research on behavioral analysis; new algorithms and applications. Topics of interest include but are not limited to:
Face recognition & biometrics Face analysis and synthesis Body action and activity recognition Gesture recognition, analysis, and synthesis Affective computing and multi-modal interaction Psychological and behavioral analysis Perceptual and cognitive aspects of non-verbal interaction Databases and tools for FG Technologies and applications related to FG Privacy and ethical issues of FG Important Dates (all AoE ) Main Track : May 25-29, 2026 Round 1 Abstract submission September 25th, 2025 Paper submission October 2nd, 2025 Notifications to authors December 11th, 2025 Round 2 Abstract submission January 9th, 2026 (only for round 2 new submissions) Paper submission January 15th, 2026 Notifications to authors April 2nd, 2026 Camera Ready (for all) April 21st, 2026 Workshops : May 25 or 29, 2026 Proposal deadline November 13th, 2025 Notification of acceptance November 27th, 2025 Tutorials : May 25 or 29, 2026 Proposal deadline January 13th, 2026 Notification of acceptance January 27th, 2026 Doctoral Consortium : May 25, 2026 Submission deadline April 9th, 2026 Notification of acceptance April 16th, 2026 Demos : Submission deadline: April 9, 2026 (Proposal and Supplemental Material) Notification of acceptance: April 16, 2026 Camera Ready Deadline: April 21, 2026 "><meta property="og:url" content="/organizers/dbb7dfe92212d0c4/"><meta property="og:title" content="László A. Jeni"><meta property="og:description" content="László A. Jeni is an Assistant Research Professor at the Robotics Institute at Carnegie Mellon University, where he leads the CUBE Lab. His research lies at the intersection of computer vision and behavioral science, focusing on modeling, understanding, and synthesizing human motion and behavior through advanced sensor technologies. He earned his master’s degree in Computer Science from Eötvös Loránd University in Hungary and his Ph.D. from the University of Tokyo, Japan, in 2012. Dr. Jeni has been recognized with several Best Paper awards, including honors at the IEEE Conference on Human System Interaction (HSI'2011) and the IEEE Conference on Automatic Face and Gesture Recognition (FG'2015). Additionally, he has received Outstanding Reviewer awards at conferences such as NeurIPS 2019, CVPR 2017, and IEEE FG 2015. With a portfolio of over 80 peer-reviewed journal and conference publications, his research contributions span a wide range of applications. His work has been supported by leading funding agencies, including the NIH, NSF, DoD, and DARPA, as well as industry giants like Facebook, Apple, Amazon, Google, and Fujitsu."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="organizers"><meta name=twitter:card content="summary"><meta name=twitter:title content="László A. Jeni"><meta name=twitter:description content="László A. Jeni is an Assistant Research Professor at the Robotics Institute at Carnegie Mellon University, where he leads the CUBE Lab. His research lies at the intersection of computer vision and behavioral science, focusing on modeling, understanding, and synthesizing human motion and behavior through advanced sensor technologies. He earned his master’s degree in Computer Science from Eötvös Loránd University in Hungary and his Ph.D. from the University of Tokyo, Japan, in 2012. Dr. Jeni has been recognized with several Best Paper awards, including honors at the IEEE Conference on Human System Interaction (HSI'2011) and the IEEE Conference on Automatic Face and Gesture Recognition (FG'2015). Additionally, he has received Outstanding Reviewer awards at conferences such as NeurIPS 2019, CVPR 2017, and IEEE FG 2015. With a portfolio of over 80 peer-reviewed journal and conference publications, his research contributions span a wide range of applications. His work has been supported by leading funding agencies, including the NIH, NSF, DoD, and DARPA, as well as industry giants like Facebook, Apple, Amazon, Google, and Fujitsu."><link rel=stylesheet href=/styles.min.4a6191fdb13e822b28e7842e2d878152a97d9475d939912197b1d47771989d8e.css type=text/css media=screen integrity="sha256-SmGR/bE+giso54QuLYeBUql9lHXZOZEhl7HUd3GYnY4="><style>:root{--color-primary-lighter:#154065;--color-primary:#102F4B;--color-primary-darker:#015a57;--color-primary-darkest:#111928;--color-secondary:#f7f8fa;--color-secondary-darker:#637381;--color-track:#154065;--color-shadow:#a6afc366}</style></head><body class=page-body><input type=checkbox class=sidebar-toggle id=sidebarToggle><header class="section-container page-header" id=pageHeader><div class="section section--short page-header__content" id=pageHeaderContent><nav id=mainNavigation class=page-header__navigation aria-labelledby=main-navigation-label><label id=main-navigation-label class=sr-only>Main Menu</label>
<label class=page-header__toggle-sidebar-label for=sidebarToggle><svg width="28" height="16" viewBox="0 0 28 16" fill="none"><rect width="22.4" height="1.33333" fill="#000"/><rect x="5.6001" y="7.33334" width="22.4" height="1.33333" fill="#000"/><rect y="14.6667" width="22.4" height="1.33333" fill="#000"/></svg>
</label><a class=page-header__title-link href=/>FG 2026</a><div class=page-header__menu-container><div id=pageHeaderMenuScriptValidator style=display:none><script>pageHeaderMenuScriptValidator.style.display="inherit"</script><ul class=header-menu><li><a class=header-menu__link href=/>FG 2026</a></li><li><a href=/cfp/ class=header-menu__link>CfP</a></li><li><a href=/doctoral_consortium/ class=header-menu__link>Doctoral Consortium</a></li><li><a href=/tutorials/ class=header-menu__link>Tutorials</a></li><li><a href=/demos/ class=header-menu__link>Demos</a></li><li><a href=/workshops/ class=header-menu__link>Workshops</a></li><li><a href=/location/ class=header-menu__link>Attend</a></li><li><a href=/organizers/ class="header-menu__link header-menu__link--active" aria-current=page>Organizers</a></li><li><a href=/sponsorship/ class=header-menu__link>Sponsorship</a></li></ul></div></div></nav></div></header><aside class=page-sidebar><nav class=page-sidebar__navigation aria-labelledby=main-navigation-label><header class=page-sidebar__header><a class=page-sidebar__heading-link href=/>FG 2026
</a><label class=page-sidebar__close-label for=sidebarToggle><svg width="17" height="17" viewBox="0 0 17 17" fill="none"><rect x=".943359" width="22.4" height="1.33333" transform="rotate(45 0.943359 0)" fill="#fff"/><rect y="15.8392" width="22.4" height="1.33333" transform="rotate(-45 0 15.8392)" fill="#fff"/></svg></label></header><ul class=sidebar-menu><li class=sidebar-menu__item><a href=/cfp/ class=sidebar-menu__link aria-label=CfP>CfP</a></li><li class=sidebar-menu__item><a href=/doctoral_consortium/ class=sidebar-menu__link aria-label="Doctoral Consortium">Doctoral Consortium</a></li><li class=sidebar-menu__item><a href=/tutorials/ class=sidebar-menu__link aria-label=Tutorials>Tutorials</a></li><li class=sidebar-menu__item><a href=/demos/ class=sidebar-menu__link aria-label=Demos>Demos</a></li><li class=sidebar-menu__item><a href=/workshops/ class=sidebar-menu__link aria-label=Workshops>Workshops</a></li><li class=sidebar-menu__item><a href=/location/ class=sidebar-menu__link aria-label=Attend>Attend</a></li><li class=sidebar-menu__item><a href=/organizers/ class="sidebar-menu__link sidebar-menu__link--active" aria-current=page aria-label=Organizers>Organizers</a></li><li class=sidebar-menu__item><a href=/sponsorship/ class=sidebar-menu__link aria-label=Sponsorship>Sponsorship</a></li></ul><div class=page-sidebar__social-links><label id=social-links-list-label-0 class=sr-only></label><ul class=social-links aria-labelledby=social-links-list-label-0></ul></div><a class="made-by-medialesson page-sidebar__made-by-link" target=_blank rel="noopener noreferrer external" href=https://gohugo.io>Made with Hugo</a></nav><label class=page-sidebar__empty-space for=sidebarToggle></label></aside><script>const header=document.getElementById("pageHeader"),intercept=document.createElement("div");intercept.setAttribute("data-observer-intercept",""),header.before(intercept);const observer=new IntersectionObserver(([e])=>{header.classList.toggle("page-header--scrolled",!e.isIntersecting)});observer.observe(intercept)</script><script>function checkWhichMenuToUse(){document.body.setAttribute("data-menu-mode","header"),pageHeaderContent.scrollWidth>pageHeaderContent.clientWidth&&document.body.setAttribute("data-menu-mode","sidebar")}new ResizeObserver(checkWhichMenuToUse).observe(document.body)</script><main class=page-main><div class=section-container><section class="section single-speaker-section"><div class=single-speaker-section__avatar><article class=speaker-avatar-container><article class=shaped-image><figure class=shaped-image__figure><svg width="100%" height="100%" viewBox="0 0 77 77"><circle fill="currentColor" cx="1.66343" cy="74.5221" r="1.66343" transform="rotate(-90 1.66343 74.5221)"/><circle fill="currentColor" cx="1.66343" cy="30.94" r="1.66343" transform="rotate(-90 1.66343 30.94)"/><circle fill="currentColor" cx="16.3021" cy="74.5221" r="1.66343" transform="rotate(-90 16.3021 74.5221)"/><circle fill="currentColor" cx="16.3021" cy="30.94" r="1.66343" transform="rotate(-90 16.3021 30.94)"/><circle fill="currentColor" cx="30.9398" cy="74.5221" r="1.66343" transform="rotate(-90 30.9398 74.5221)"/><circle fill="currentColor" cx="30.9398" cy="30.94" r="1.66343" transform="rotate(-90 30.9398 30.94)"/><circle fill="currentColor" cx="45.5785" cy="74.5221" r="1.66343" transform="rotate(-90 45.5785 74.5221)"/><circle fill="currentColor" cx="45.5785" cy="30.94" r="1.66343" transform="rotate(-90 45.5785 30.94)"/><circle fill="currentColor" cx="60.2162" cy="74.5216" r="1.66343" transform="rotate(-90 60.2162 74.5216)"/><circle fill="currentColor" cx="74.6634" cy="74.5216" r="1.66343" transform="rotate(-90 74.6634 74.5216)"/><circle fill="currentColor" cx="60.2162" cy="30.9399" r="1.66343" transform="rotate(-90 60.2162 30.9399)"/><circle fill="currentColor" cx="74.6634" cy="30.9399" r="1.66343" transform="rotate(-90 74.6634 30.9399)"/><circle fill="currentColor" cx="1.66343" cy="59.8839" r="1.66343" transform="rotate(-90 1.66343 59.8839)"/><circle fill="currentColor" cx="1.66343" cy="16.3017" r="1.66343" transform="rotate(-90 1.66343 16.3017)"/><circle fill="currentColor" cx="16.3021" cy="59.8839" r="1.66343" transform="rotate(-90 16.3021 59.8839)"/><circle fill="currentColor" cx="16.3021" cy="16.3017" r="1.66343" transform="rotate(-90 16.3021 16.3017)"/><circle fill="currentColor" cx="30.9398" cy="59.8839" r="1.66343" transform="rotate(-90 30.9398 59.8839)"/><circle fill="currentColor" cx="30.9398" cy="16.3017" r="1.66343" transform="rotate(-90 30.9398 16.3017)"/><circle fill="currentColor" cx="45.5785" cy="59.8839" r="1.66343" transform="rotate(-90 45.5785 59.8839)"/><circle fill="currentColor" cx="45.5785" cy="16.3017" r="1.66343" transform="rotate(-90 45.5785 16.3017)"/><circle fill="currentColor" cx="60.2162" cy="59.8839" r="1.66343" transform="rotate(-90 60.2162 59.8839)"/><circle fill="currentColor" cx="74.6634" cy="59.8839" r="1.66343" transform="rotate(-90 74.6634 59.8839)"/><circle fill="currentColor" cx="60.2162" cy="16.3017" r="1.66343" transform="rotate(-90 60.2162 16.3017)"/><circle fill="currentColor" cx="74.6634" cy="16.3017" r="1.66343" transform="rotate(-90 74.6634 16.3017)"/><circle fill="currentColor" cx="1.66343" cy="45.2455" r="1.66343" transform="rotate(-90 1.66343 45.2455)"/><circle fill="currentColor" cx="1.66343" cy="1.66344" r="1.66343" transform="rotate(-90 1.66343 1.66344)"/><circle fill="currentColor" cx="16.3021" cy="45.2455" r="1.66343" transform="rotate(-90 16.3021 45.2455)"/><circle fill="currentColor" cx="16.3021" cy="1.66342" r="1.66343" transform="rotate(-90 16.3021 1.66342)"/><circle fill="currentColor" cx="30.9398" cy="45.2455" r="1.66343" transform="rotate(-90 30.9398 45.2455)"/><circle fill="currentColor" cx="30.9398" cy="1.66342" r="1.66343" transform="rotate(-90 30.9398 1.66342)"/><circle fill="currentColor" cx="45.5785" cy="45.2455" r="1.66343" transform="rotate(-90 45.5785 45.2455)"/><circle fill="currentColor" cx="45.5785" cy="1.66344" r="1.66343" transform="rotate(-90 45.5785 1.66344)"/><circle fill="currentColor" cx="60.2162" cy="45.2458" r="1.66343" transform="rotate(-90 60.2162 45.2458)"/><circle fill="currentColor" cx="74.6634" cy="45.2458" r="1.66343" transform="rotate(-90 74.6634 45.2458)"/><circle fill="currentColor" cx="60.2162" cy="1.66371" r="1.66343" transform="rotate(-90 60.2162 1.66371)"/><circle fill="currentColor" cx="74.6634" cy="1.66371" r="1.66343" transform="rotate(-90 74.6634 1.66371)"/></svg></figure><img class=shaped-image__image src=/organizers/dbb7dfe92212d0c4/avatar.webp alt="László A. Jeni" width height></article></article></div><div class=single-speaker-section__biography><article class=speaker-biography><h1 class="h1 speaker-biography__name">László A. Jeni</h1><h2 class=speaker-biography__slogan>Carnegie Mellon University, USA</h2><p class=speaker-biography__description>László A. Jeni is an Assistant Research Professor at the Robotics Institute at Carnegie Mellon University, where he leads the CUBE Lab. His research lies at the intersection of computer vision and behavioral science, focusing on modeling, understanding, and synthesizing human motion and behavior through advanced sensor technologies. He earned his master's degree in Computer Science from Eötvös Loránd University in Hungary and his Ph.D. from the University of Tokyo, Japan, in 2012. Dr. Jeni has been recognized with several Best Paper awards, including honors at the IEEE Conference on Human System Interaction (HSI'2011) and the IEEE Conference on Automatic Face and Gesture Recognition (FG'2015). Additionally, he has received Outstanding Reviewer awards at conferences such as NeurIPS 2019, CVPR 2017, and IEEE FG 2015. With a portfolio of over 80 peer-reviewed journal and conference publications, his research contributions span a wide range of applications. His work has been supported by leading funding agencies, including the NIH, NSF, DoD, and DARPA, as well as industry giants like Facebook, Apple, Amazon, Google, and Fujitsu.</p></article></div></section></div></main><footer class=section-container><section class="section section--short page-footer-section"><div class=page-footer-section__start><label id=social-links-list-label-1 class=sr-only>Social media links</label><ul class=social-links aria-labelledby=social-links-list-label-1></ul></div><ul class=footer-menu></ul><div class=page-footer-section__end><a class="made-by-medialesson page-footer-section__made-by-link" target=_blank rel="noopener noreferrer external" href=https://gohugo.io>Made with Hugo</a></div></section></footer></body></html>